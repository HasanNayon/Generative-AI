# Generative AI - Learning Journey

Welcome to my **Generative AI** repository! This is where I document my progress and learning as I dive into the world of Generative Artificial Intelligence. Through this repository, I'll share my projects, insights, experiments, and key takeaways related to various topics, including Large Language Models (LLMs), prompt engineering, fine-tuning, RAG (Retrieval-Augmented Generation), LLMOps, and much more.

## About

Generative AI refers to the subset of artificial intelligence that involves training models to create new content based on existing data. This repository focuses on exploring the various facets of **Generative AI**, specifically Large Language Models (LLMs), their applications, and techniques like fine-tuning, prompt engineering, and building AI agents.

### Key Topics Covered:
- **Building Basic LLM Applications**
- **Prompt Engineering**
- **Retrieval-Augmented Generation (RAG)**
- **Fine-tuning Models**
- **AI Agents**
- **LLMOps**
- **Miscellaneous Techniques and Tools**

## Technologies Used

- **Python**
- **TensorFlow & PyTorch**
- **Hugging Face Transformers**
- **LangChain**
- **OpenAI GPT API**
- **Ollama**
- **LlamaIndex**
- **APIs for LLMs**
- **Docker (for LLMOps)**

## Learning Topics

Here are the key areas I've focused on in my **Generative AI** learning journey:

### 1. **Building Basic LLM Applications**
   - **Open Source vs Closed Source LLMs**: Exploring the differences between open-source and proprietary LLM models.
   - **Using LLM APIs**: Integrating and utilizing LLM APIs such as OpenAI's GPT and other cloud-based services.
   - **LangChain**: A framework to develop applications with LLMs, enabling the creation of conversational agents and pipelines.
   - **HuggingFace**: Leveraging the HuggingFace ecosystem for pre-trained models, tokenizers, and pipelines.
   - **Ollama**: Experimenting with Ollama's framework for conversational AI and other LLM-based applications.

### 2. **Prompt Engineering**
   - Developing effective prompt strategies to enhance the performance and accuracy of generative models in various tasks like text generation, summarization, and code generation.

### 3. **Retrieval-Augmented Generation (RAG)**
   - Implementing RAG to combine the generative power of LLMs with external knowledge retrieval to improve response quality and context awareness.

### 4. **Fine-Tuning**
   - Understanding the process of fine-tuning pre-trained models on domain-specific data to improve model performance and adapt them to specific tasks.

### 5. **AI Agents**
   - Building intelligent agents using LLMs, capable of decision-making, task execution, and interacting with external systems like APIs.

### 6. **LLMOps**
   - Exploring operational aspects of LLMs, including deployment, scaling, and monitoring, as well as integrating CI/CD pipelines to manage model updates and deployments.

### 7. **Miscellaneous**
   - Exploring other interesting topics and tools in the generative AI space, such as model explainability, data preprocessing, and advanced techniques for optimizing LLM performance.

## Learning Notes

This section will be filled with my reflections, notes, and key takeaways as I work through each topic. The notes will cover:
- **Key Concepts**: Definitions, techniques, and methodologies.
- **Challenges Faced**: Difficulties and obstacles I encounter while working with generative models.
- **Solutions and Optimizations**: Ideas for improving model performance and fine-tuning strategies.
- **Important Papers and Resources**: Key papers, tutorials, and guides that I reference during my learning.
